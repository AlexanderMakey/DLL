{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adcb6898",
   "metadata": {},
   "source": [
    "## Инструменты\n",
    "- Python\n",
    "- приближённый KNN (nmslib/faiss/scann)\n",
    "- модели из Hugging Face (Transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75900f8",
   "metadata": {},
   "source": [
    "[Рейтинг русскоязычных энкодеров предложений](https://habr.com/ru/articles/669674/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3afcfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "# нужно еще это тут\n",
    "# pip install ipywidgets\n",
    "import torch\n",
    "import nmslib\n",
    "# работает на версии python 3.8.17\n",
    "# https://stackoverflow.com/questions/71242919/pip-install-results-in-this-error-cl-exe-failed-with-exit-code-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58882628",
   "metadata": {},
   "source": [
    "## Цель\n",
    "- реализовать задачу классификации на основе BERT-like модели и KNN на данных [Russian Intents Dataset](https://www.kaggle.com/datasets/constantinwerner/qa-intents-dataset-university-domain) с Kaggle.\n",
    "- научиться создавать классификаторы текстов в условиях большого числа маленьких классов, состоящих из коротких текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cf6827",
   "metadata": {},
   "source": [
    "## Ожидаемый результат\n",
    "- код для создания поискового векторного индекса\n",
    "- логика определения класса на основе близости к обучающим объектам (по ближайшему, по топ-N ближайших, и т. п.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee0ce0",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e80a7f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_table(\n",
    "    'qa-intents-dataset-university-domain/dataset_train.tsv',\n",
    "    header=None,names=['txt','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8608d149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txt</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>мне нужна справка</td>\n",
       "      <td>statement_general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>оформить справку</td>\n",
       "      <td>statement_general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>взять справку</td>\n",
       "      <td>statement_general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>справку как получить</td>\n",
       "      <td>statement_general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>справку ммф где получаться</td>\n",
       "      <td>statement_general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13225</th>\n",
       "      <td>тупой</td>\n",
       "      <td>smalltalk_abuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13226</th>\n",
       "      <td>робот  бестолковый</td>\n",
       "      <td>smalltalk_abuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13227</th>\n",
       "      <td>несообразительный</td>\n",
       "      <td>smalltalk_abuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13228</th>\n",
       "      <td>ты  бестолковый</td>\n",
       "      <td>smalltalk_abuse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13229</th>\n",
       "      <td>бот  несообразительный</td>\n",
       "      <td>smalltalk_abuse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13230 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              txt                  c\n",
       "0               мне нужна справка  statement_general\n",
       "1                оформить справку  statement_general\n",
       "2                   взять справку  statement_general\n",
       "3            справку как получить  statement_general\n",
       "4      справку ммф где получаться  statement_general\n",
       "...                           ...                ...\n",
       "13225                       тупой    smalltalk_abuse\n",
       "13226          робот  бестолковый    smalltalk_abuse\n",
       "13227           несообразительный    smalltalk_abuse\n",
       "13228             ты  бестолковый    smalltalk_abuse\n",
       "13229      бот  несообразительный    smalltalk_abuse\n",
       "\n",
       "[13230 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be390cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_table(\n",
    "    'qa-intents-dataset-university-domain/dataset_test.tsv',\n",
    "    header=None,names=['txt','c'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c231560e",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37b03e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output['last_hidden_state']\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c472fb42",
   "metadata": {},
   "source": [
    "## KNN\n",
    "### код для создания поискового векторного индекса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0b1f3e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeding(MODEL_NAME, train, test):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    model = AutoModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    train_token = tokenizer(train['txt'].tolist(), padding=True, return_tensors='pt', max_length = 32, truncation=True) \n",
    "    test_token = tokenizer(test['txt'].tolist(), padding=True, return_tensors='pt', max_length = 32, truncation=True) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        train_embeding = mean_pooling(model(**train_token), train_token['attention_mask'])\n",
    "        test_embeding = mean_pooling(model(**test_token), test_token['attention_mask'])\n",
    "    return train_embeding, test_embeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "23ddfaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(train_embeding):\n",
    "    index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "    index.addDataPointBatch(train_embeding, ids=list(range(len(train_embeding))))\n",
    "    index.createIndex({'post': 2}, print_progress=True)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70727b6",
   "metadata": {},
   "source": [
    "### логика определения класса на основе близости к обучающим объектам, а именно по ближайшему"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "5513570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result(index, test_embeding, test, train):\n",
    "\n",
    "    right = 0\n",
    "    # кол-во совпадений\n",
    "\n",
    "    for n, test_item in enumerate(test_embeding):\n",
    "        target = test.iloc[n].c\n",
    "        predicted = None\n",
    "        id_, dist = index.knnQuery(test_item, k=1)\n",
    "        dict_ = {}\n",
    "        for i, d in zip(id_, dist):\n",
    "            exist_ = 0\n",
    "            if train.iloc[i].c in dict_.keys():\n",
    "                exist_ = dict_[train.iloc[i].c]\n",
    "            dict_[train.iloc[i].c] = exist_ + 1 - d\n",
    "        predicted = max(dict_, key=dict_.get)\n",
    "\n",
    "        if target == predicted:\n",
    "            right += 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return right / len(test_embeding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c6e4a6",
   "metadata": {},
   "source": [
    "## sentence-transformers/paraphrase-xlm-r-multilingual-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a27d2093",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'sentence-transformers/paraphrase-xlm-r-multilingual-v1'\n",
    "train_embeding, test_embeding = get_embeding(MODEL_NAME, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "eb422e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8856172140430351"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = get_index(train_embeding)\n",
    "result = get_result(index, test_embeding, test, train)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbba85d0",
   "metadata": {},
   "source": [
    "## sentence-transformers/all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "55a1ebd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "train_embeding, test_embeding = get_embeding(MODEL_NAME, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f2fe65f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9003397508493771"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = get_index(train_embeding)\n",
    "result = get_result(index, test_embeding, test, train)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62396460",
   "metadata": {},
   "source": [
    "## intfloat/multilingual-e5-large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9b10f224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 418/418 [00:00<00:00, 69.7kB/s]\n",
      "Downloading (…)tencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:00<00:00, 6.37MB/s]\n",
      "Downloading tokenizer.json: 100%|██████████| 17.1M/17.1M [00:02<00:00, 7.91MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 280/280 [00:00<00:00, 38.4kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 690/690 [00:00<00:00, 99.5kB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 2.24G/2.24G [04:07<00:00, 9.05MB/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'intfloat/multilingual-e5-large'\n",
    "train_embeding, test_embeding = get_embeding(MODEL_NAME, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "4cf7a67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.942242355605889\n"
     ]
    }
   ],
   "source": [
    "index = get_index(train_embeding)\n",
    "result = get_result(index, test_embeding, test, train)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0c70c",
   "metadata": {},
   "source": [
    "## inkoziev/sbert_synonymy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "de61ab3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 410/410 [00:00<?, ?B/s] \n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 1.08M/1.08M [00:00<00:00, 2.19MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 2.41M/2.41M [00:00<00:00, 8.55MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 125/125 [00:00<00:00, 10.9kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 684/684 [00:00<00:00, 45.9kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 117M/117M [00:11<00:00, 9.88MB/s] \n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'inkoziev/sbert_synonymy'\n",
    "train_embeding, test_embeding = get_embeding(MODEL_NAME, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "94f77967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9161947904869762\n"
     ]
    }
   ],
   "source": [
    "index = get_index(train_embeding)\n",
    "result = get_result(index, test_embeding, test, train)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7130ff0",
   "metadata": {},
   "source": [
    "## cointegrated/rubert-tiny2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "203f9e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'cointegrated/rubert-tiny2'\n",
    "train_embeding, test_embeding = get_embeding(MODEL_NAME, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "837c1922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8844847112117781"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = get_index(train_embeding)\n",
    "result = get_result(index, test_embeding, test, train)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc58f713",
   "metadata": {},
   "source": [
    "## ai-forever/sbert_large_nlu_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "27ccee6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 323/323 [00:00<00:00, 53.9kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 655/655 [00:00<?, ?B/s] \n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 1.78M/1.78M [00:00<00:00, 2.97MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 28.5kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 1.71G/1.71G [02:52<00:00, 9.91MB/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'ai-forever/sbert_large_nlu_ru'\n",
    "train_embeding, test_embeding = get_embeding(MODEL_NAME, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "532ddc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8573046432616082\n"
     ]
    }
   ],
   "source": [
    "index = get_index(train_embeding)\n",
    "result = get_result(index, test_embeding, test, train)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88387604",
   "metadata": {},
   "source": [
    "## xlm-roberta-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "17736d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)lve/main/config.json: 100%|██████████| 615/615 [00:00<00:00, 123kB/s]\n",
      "Downloading (…)tencepiece.bpe.model: 100%|██████████| 5.07M/5.07M [00:00<00:00, 5.28MB/s]\n",
      "Downloading (…)/main/tokenizer.json: 100%|██████████| 9.10M/9.10M [00:01<00:00, 8.75MB/s]\n",
      "Downloading model.safetensors: 100%|██████████| 1.12G/1.12G [02:02<00:00, 9.14MB/s]\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'xlm-roberta-base'\n",
    "train_embeding, test_embeding = get_embeding(MODEL_NAME, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d1ca744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8731596828992072\n"
     ]
    }
   ],
   "source": [
    "index = get_index(train_embeding)\n",
    "result = get_result(index, test_embeding, test, train)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc465d6",
   "metadata": {},
   "source": [
    "## DeepPavlov/rubert-base-cased-sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2792a7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)okenizer_config.json: 100%|██████████| 24.0/24.0 [00:00<00:00, 6.00kB/s]\n",
      "Downloading (…)lve/main/config.json: 100%|██████████| 642/642 [00:00<00:00, 161kB/s]\n",
      "Downloading (…)solve/main/vocab.txt: 100%|██████████| 1.65M/1.65M [00:00<00:00, 2.69MB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 28.0kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 711M/711M [01:17<00:00, 9.18MB/s] \n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = 'DeepPavlov/rubert-base-cased-sentence'\n",
    "train_embeding, test_embeding = get_embeding(MODEL_NAME, train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9982f870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8958097395243488\n"
     ]
    }
   ],
   "source": [
    "index = get_index(train_embeding)\n",
    "result = get_result(index, test_embeding, test, train)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c5eb3d",
   "metadata": {},
   "source": [
    "## bert-base-multilingual-cased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e67a11b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading model.safetensors: 100%|██████████| 714M/714M [01:13<00:00, 9.68MB/s] \n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "MODEL_NAME = 'bert-base-multilingual-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BertModel.from_pretrained(MODEL_NAME)\n",
    "\n",
    "train_token = tokenizer(train['txt'].tolist(), padding=True, return_tensors='pt', max_length = 32, truncation=True) \n",
    "test_token = tokenizer(test['txt'].tolist(), padding=True, return_tensors='pt', max_length = 32, truncation=True) \n",
    "\n",
    "with torch.no_grad():\n",
    "    train_embeding = mean_pooling(model(**train_token), train_token['attention_mask'])\n",
    "    test_embeding = mean_pooling(model(**test_token), test_token['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9af4cc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8720271800679502\n"
     ]
    }
   ],
   "source": [
    "index = get_index(train_embeding)\n",
    "result = get_result(index, test_embeding, test, train)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30f2f5f",
   "metadata": {},
   "source": [
    "## Итог\n",
    "- базовые модели (bert-base-multilingual-cased, xlm-roberta-base) дают средний результат\n",
    "- модели предназначенные чисто под русский язык (ai-forever/sbert_large_nlu_ru, cointegrated/rubert-tiny2) тоже не самые лучшие\n",
    "- хороший результат дала авторская модель (inkoziev/sbert_synonymy) специально сделаная для сравнения похожести русских предложений\n",
    "- и очень хороший результат (точность 94%) дала модель с большим объемом парамметров (intfloat/multilingual-e5-large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124895d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
